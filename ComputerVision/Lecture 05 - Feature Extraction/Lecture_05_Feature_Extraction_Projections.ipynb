{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrehochuli/teaching/blob/main/ComputerVision/Lecture%2005%20-%20Feature%20Extraction/Lecture_05_Feature_Extraction_Projections.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "metadata": {
        "id": "OzOsjpFd3pQy",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#Auxiliary Function to plot side by side\n",
        "def plot_sidebyside(img_list,titles,colormap=None,figsize=(12,6)):\n",
        "  n = len(img_list)\n",
        "  figure, axis = plt.subplots(1, n, figsize=figsize)\n",
        "\n",
        "  for i in range(n):\n",
        "    axis[i].imshow(img_list[i], cmap=colormap)\n",
        "    axis[i].set_title(titles[i])\n",
        "    axis[i].axis('off')\n",
        "  # Combine all the operations and display\n",
        "  plt.show()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "umVzbjeoJoJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Character Dataset\n",
        "First, we will create an Isolated Character Dataset to work with feature extraction"
      ],
      "metadata": {
        "id": "wuluuaiwwF8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "char_labels = []\n",
        "char_dataset = []\n",
        "\n",
        "#use a ascii codes to determine each char\n",
        "\n",
        "#0 to 9\n",
        "for n in range(48,58):\n",
        "  char_labels.append(chr(n))\n",
        "\n",
        "#A....Z\n",
        "for n in range(65,91):\n",
        "  char_labels.append(chr(n))\n",
        "\n",
        "# font\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "pt = (50, 50)\n",
        "fontScale = 2\n",
        "color = (255, 255, 255)\n",
        "thickness = 2\n",
        "\n",
        "#Create char images [0,1,2......w,x,z]\n",
        "for C in char_labels:\n",
        "  img = np.zeros((100,100),np.uint8)\n",
        "\n",
        "  #Write the character C on the image\n",
        "  img = cv2.putText(img, C, pt, font,\n",
        "                    fontScale, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "  #Compute the bbox and crop\n",
        "  a = np.where(img != 0)\n",
        "  bbox = np.min(a[0]), np.max(a[0]), np.min(a[1]), np.max(a[1])\n",
        "\n",
        "  img = img[bbox[0]:bbox[1], bbox[2]:bbox[3]]\n",
        "  char_dataset.append(img)\n",
        "\n",
        "#Plotting some images\n",
        "plot_sidebyside(char_dataset[19:30],char_labels[19:30],colormap='gray')\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Whp_hoXJJoJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Image Size as Feature\n",
        "\n",
        "Considering the Character Dataset, one can argue that the image's height and width should be an interesting feature to determine its content (A, B...Z...0...9).\n",
        "\n",
        "Below we shows that these features have no sufficient representation once several labels are mapped to the same region on the feature space. It is called a non-discriminative feature."
      ],
      "metadata": {
        "id": "qyWLC2SOyDm3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "features = [(lambda x: x.shape)(x) for x in char_dataset]\n",
        "y, x = zip(*features)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.scatter(x, y)\n",
        "plt.title(\"Image Size Feature\")\n",
        "plt.xlabel(\"Width\")\n",
        "plt.ylabel(\"Height\")\n",
        "\n",
        "for i in range(len(x)):\n",
        "  #print('[%d,%d,%s] ' % (x[i],y[i],chars[i]), end='')\n",
        "  plt.text(x=x[i], y=y[i], s=char_labels[i])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "EIcBGifkJoJ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "horiz_features = []\n",
        "vert_features = []\n",
        "hv_features = []\n",
        "\n",
        "for img in char_dataset:\n",
        "\n",
        "  #Normalization\n",
        "  img = cv2.resize(img,(28,28))\n",
        "  height, width = img.shape\n",
        "\n",
        "  # Sum the value lines\n",
        "  vert = np.sum(img, axis=0)\n",
        "  horiz = np.sum(img, axis=1)\n",
        "\n",
        "  # Normalize 0-255\n",
        "  vert = vert/255\n",
        "  horiz = horiz/255\n",
        "  both = np.concatenate([vert,horiz],axis = 0)\n",
        "\n",
        "  horiz_features.append(vert)\n",
        "  vert_features.append(horiz)\n",
        "  hv_features.append(both)\n",
        "\n",
        "\n",
        "  # create a black image with zeros\n",
        "  vert_proj = np.zeros((28,28),dtype=np.uint8)\n",
        "  horiz_proj = np.zeros((28,28),dtype=np.uint8)\n",
        "  both_proj = np.zeros((28,56),dtype=np.uint8)\n",
        "\n",
        "\n",
        "  # Make the vertical projection histogram\n",
        "  for idx, value in enumerate(vert):\n",
        "      cv2.line(vert_proj, (idx, 0), (idx, height-int(value)), (255,255,255), 1)\n",
        "\n",
        "  for idx, value in enumerate(horiz):\n",
        "      cv2.line(horiz_proj, (idx, 0), (idx, height-int(value)), (255,255,255), 1)\n",
        "\n",
        "  for idx, value in enumerate(both):\n",
        "      cv2.line(both_proj, (idx, 0), (idx, height-int(value)), (255,255,255), 1)\n",
        "\n",
        "\n",
        "  plot_sidebyside([img,vert_proj,horiz_proj,both_proj],['Input','Vertical','Horizontal','Both'],'gray',(8,8))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-2qDlTEUJoJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Reduction and Visualization\n",
        "\n",
        "Lets use the PCA to better understand the features and visualize them"
      ],
      "metadata": {
        "id": "NIKSHYMr2SSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_features(pca_features,labels,title='PCA Plot',figsize=(12,8)):\n",
        "\n",
        "  plt.figure(figsize=figsize)\n",
        "  x, y = zip(*pca_features)\n",
        "  plt.scatter(x, y)\n",
        "\n",
        "  for i in range(len(x)):\n",
        "    plt.text(x=x[i], y=y[i], s=labels[i])\n",
        "\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "6k-ko28X2pKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "reduced_data = PCA(n_components=2).fit_transform(vert_features)\n",
        "plot_features(reduced_data,char_labels,'PCA of Vertical Proj')\n",
        "\n",
        "reduced_data = PCA(n_components=2).fit_transform(horiz_features)\n",
        "plot_features(reduced_data,char_labels,'PCA of Horizontal Proj')\n",
        "\n",
        "reduced_data = PCA(n_components=2).fit_transform(hv_features)\n",
        "plot_features(reduced_data,char_labels,'PCA of Horizontal and Vertical Proj')\n",
        "\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4E_SAr6_JoJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA Components Explanation"
      ],
      "metadata": {
        "id": "WMvvxk8-8Zuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=28)\n",
        "reduced_data = pca.fit_transform(hv_features)\n",
        "percentage_var_explained = pca.explained_variance_ / np.sum(pca.explained_variance_)\n",
        "cum_var_explained = np.cumsum(percentage_var_explained)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.clf()\n",
        "plt.plot(cum_var_explained, linewidth=2)\n",
        "plt.axis('tight')\n",
        "plt.grid()\n",
        "plt.xlabel('n_components')\n",
        "plt.ylabel('Cumulative_explained_variance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BysEqWFe7Waf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The MNIST Dataset\n",
        "\n",
        "*   Handwritten Digits\n",
        "*   Challenges: Angle, Size, Noise, Broken...\n",
        "\n"
      ],
      "metadata": {
        "id": "gnG6MNHz4fbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(x_train[0].shape)\n",
        "for i in range(0,5):\n",
        "  idx = i*10\n",
        "\n",
        "  plot_sidebyside(x_train[idx:idx+10],y_train[idx:idx+10],'gray')\n"
      ],
      "metadata": {
        "id": "FQ8ERBvw4MCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pratice 01\n",
        "  Produce the features learned until now and compute the feature space using PCA."
      ],
      "metadata": {
        "id": "8I62ukrZ5-dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)\n",
        "print(x_train.shape)\n",
        "data = np.reshape(x_train,(60000,28*28))\n",
        "reduced_data = pca.fit_transform(data)\n",
        "\n",
        "plot_features(reduced_data[:500],y_train[:500],'Original Space')"
      ],
      "metadata": {
        "id": "LHrlvU0W59sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's up to you!\n",
        "\n",
        "Implement vertical and horizontal projection and evaluate the feature space!"
      ],
      "metadata": {
        "id": "LcdRsS80BQI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pratice 02\n",
        "Back to the license plate recognition of Lecture 04. Extract the horizontal and vertical projection and evaluate against your approach"
      ],
      "metadata": {
        "id": "tvDbY7urCIJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZ60i9CpBP3m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}