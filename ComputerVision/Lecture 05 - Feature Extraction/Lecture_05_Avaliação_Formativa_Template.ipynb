{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yz6nCqCFLPsc",
        "jjqi9vCbVD6L"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrehochuli/teaching/blob/main/ComputerVision/Lecture%2005%20-%20Feature%20Extraction/Lecture_05_Avalia%C3%A7%C3%A3o_Formativa_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Auxiliary Functions"
      ],
      "metadata": {
        "id": "yz6nCqCFLPsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2, math\n",
        "import matplotlib.pyplot as plt\n",
        "#Keras to import datasets, not for deep learning (yet)\n",
        "from tensorflow import keras\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import metrics, preprocessing\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import skimage.feature as feature\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "8ffCHWAey-Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Auxiliary Function to plot side by side\n",
        "#@Author: Prof. André Hochuli\n",
        "#Visualiza um lista de figuras lado a lado, facilitando a comparação qualitativa\n",
        "def plot_sidebyside(img_list,titles=None,colormap=None,figsize=(12,6)):\n",
        "  n = len(img_list)\n",
        "  figure, axis = plt.subplots(1, n, figsize=figsize)\n",
        "\n",
        "  if titles is None:\n",
        "    titles = []\n",
        "    A = ord('A')\n",
        "    for i in range(n):\n",
        "      titles.append(chr(A+i))\n",
        "\n",
        "  for i in range(n):\n",
        "    axis[i].imshow(img_list[i], cmap=colormap)\n",
        "    axis[i].set_title(titles[i])\n",
        "    axis[i].axis('off')\n",
        "  # Combine all the operations and display\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "aXLNCO7kC8zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@Author: Prof. André Hochuli\n",
        "#Compila os resultados para analises qualitativas e quantitativas\n",
        "def performance_evaluation(x_test, y_test, predictions, class_names, info_message):\n",
        "\n",
        "    print(f\"Evaluation of {info_message}\")\n",
        "    print(metrics.classification_report(y_test, predictions))\n",
        "\n",
        "\n",
        "    # Matriz de confusão\n",
        "    disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
        "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # Imagens classificadas corretamente\n",
        "    correct_idx = np.where(y_test == predictions)[0]\n",
        "    n_correct = min(10, len(correct_idx))\n",
        "    if n_correct > 0:\n",
        "        plt.figure(figsize=(22, 4))\n",
        "        for i in range(n_correct):\n",
        "            idx = correct_idx[i]\n",
        "            plt.subplot(1, n_correct, i+1)\n",
        "            plt.imshow(x_test[idx], cmap='gray', interpolation='nearest')\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"Lbl:{y_test[idx]} Pred:{predictions[idx]}\")\n",
        "        plt.suptitle(\"Correct Predictions\", fontsize=16, fontweight='bold', color='white', backgroundcolor='green')\n",
        "        plt.show()\n",
        "\n",
        "    #Imagens classificadas incorretamente\n",
        "    wrong_idx = np.where(y_test != predictions)[0]\n",
        "    n_wrong = min(10, len(wrong_idx))\n",
        "    if n_wrong > 0:\n",
        "        plt.figure(figsize=(22, 4))\n",
        "        for i in range(n_wrong):\n",
        "            idx = wrong_idx[i]\n",
        "            plt.subplot(1, n_wrong, i+1)\n",
        "            plt.imshow(x_test[idx], cmap='gray', interpolation='nearest')\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"Lbl:{y_test[idx]} Pred:{predictions[idx]}\")\n",
        "        plt.suptitle(\"Wrong Predictions\", fontsize=16, fontweight='bold', color='white', backgroundcolor='red')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    #Exibir exemplo de cada classe\n",
        "    unique_classes = np.unique(y_test)\n",
        "    plt.figure(figsize=(22, 4))\n",
        "    for i, cls in enumerate(unique_classes):\n",
        "        idx = np.where(y_test == cls)[0][0]  # primeiro índice da classe\n",
        "        plt.subplot(1, len(unique_classes), i+1)\n",
        "        plt.imshow(x_test[idx], cmap='gray', interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"{i}-{class_names[cls]}\")\n",
        "    plt.suptitle(\"Example of each class\", fontsize=16, fontweight='bold', color='black', backgroundcolor='yellow')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "k7qqZv31fMV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_shuffle(X_train, y_train, X_test, y_test, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Shuffle train\n",
        "    idx_train = np.random.permutation(len(y_train))\n",
        "    X_train_shuffled = X_train[idx_train]\n",
        "    y_train_shuffled = y_train[idx_train]\n",
        "\n",
        "    # Shuffle test\n",
        "    idx_test = np.random.permutation(len(y_test))\n",
        "    X_test_shuffled = X_test[idx_test]\n",
        "    y_test_shuffled = y_test[idx_test]\n",
        "\n",
        "    return X_train_shuffled, y_train_shuffled, X_test_shuffled, y_test_shuffled"
      ],
      "metadata": {
        "id": "7WxJQVr24HNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def random_undersampling(X, y, random_state=42):\n",
        "\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Contar amostras por classe\n",
        "    class_counts = Counter(y)\n",
        "    min_count = min(class_counts.values())\n",
        "\n",
        "    X_resampled = []\n",
        "    y_resampled = []\n",
        "\n",
        "    for cls in class_counts.keys():\n",
        "        idx_cls = np.where(y == cls)[0]\n",
        "        # Seleciona min_count índices aleatoriamente\n",
        "        selected_idx = np.random.choice(idx_cls, size=min_count, replace=False)\n",
        "        X_resampled.append(X[selected_idx])\n",
        "        y_resampled.append(y[selected_idx])\n",
        "\n",
        "    X_resampled = np.concatenate(X_resampled, axis=0)\n",
        "    y_resampled = np.concatenate(y_resampled, axis=0)\n",
        "\n",
        "    # Embaralhar os dados novamente\n",
        "    shuffle_idx = np.random.permutation(len(y_resampled))\n",
        "    X_resampled = X_resampled[shuffle_idx]\n",
        "    y_resampled = y_resampled[shuffle_idx]\n",
        "\n",
        "    return X_resampled, y_resampled\n"
      ],
      "metadata": {
        "id": "sqWuwZWMwkF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_swedish_leaf(base_dir):\n",
        "    dataset_url = \"http://www.ppgia.pucpr.br/~aghochuli/swedish_leaf.zip\"\n",
        "    zip_path = \"swedish_leaf.zip\"\n",
        "\n",
        "    if not os.path.exists(base_dir):\n",
        "      print(\"Downloading...\")\n",
        "      os.system(f\"wget -O {zip_path} {dataset_url}\")\n",
        "      os.system(f\"unzip {zip_path}\")\n",
        "      #os.remove(zip_path)\n",
        "      print(f\"Dataset extracted to: {base_dir}\")\n",
        "    else:\n",
        "      print(f\"Dataset already available at: {base_dir}\")\n",
        "\n",
        "def load_swedish_leaf():\n",
        "\n",
        "    base_dir = \"swedish_leaf\"\n",
        "\n",
        "    retrieve_swedish_leaf(base_dir)\n",
        "\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for i in range(1, 9):\n",
        "        leaf_dir = os.path.join(base_dir, f'leaf{i}')\n",
        "        if os.path.isdir(leaf_dir):\n",
        "\n",
        "            for filename in os.listdir(leaf_dir):\n",
        "                if filename.endswith('.png'):\n",
        "                    img_path = os.path.join(leaf_dir, filename)\n",
        "                    try:\n",
        "                        # Carrega em escala de cinza\n",
        "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                        # Redimensiona para 128x128\n",
        "                        img_resized = cv2.resize(img, (128, 128))\n",
        "\n",
        "                        x_train.append(img_resized)\n",
        "                        y_train.append(i - 1)  # Labels de 0 a 7\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "    # Holdout 70/30 estratificado\n",
        "    X_train, X_test, y_train_split, y_test_split = train_test_split(\n",
        "        x_train, y_train,\n",
        "        test_size=0.3,\n",
        "        random_state=42,\n",
        "        stratify=y_train\n",
        "    )\n",
        "\n",
        "    class_names = {\n",
        "      0: 'Ulmus carpinifolia',\n",
        "      1: 'Acer',\n",
        "      2: 'Salix aurita',\n",
        "      3: 'Quercus',\n",
        "      4: 'Alnus incana',\n",
        "      5: 'Betula pubescens',\n",
        "      6: 'Salix alba \\'Sericea\\'',\n",
        "      7: 'Populus tremula'\n",
        "    }\n",
        "\n",
        "    return np.array(X_train),np.array(y_train_split),np.array(X_test),np.array(y_test_split), class_names"
      ],
      "metadata": {
        "id": "DGVNNhXEd7Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_paper_rock_scissors(base_dir):\n",
        "    dataset_url = \"http://www.ppgia.pucpr.br/~aghochuli/paper-rock-scissors.zip\"\n",
        "    zip_path = \"paper-rock-scissors.zip\"\n",
        "\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(\"Downloading...\")\n",
        "        os.system(f\"wget -O {zip_path} {dataset_url}\")\n",
        "        os.system(f\"unzip {zip_path}\")\n",
        "        #os.remove(zip_path)\n",
        "        print(f\"Dataset extracted to: {base_dir}\")\n",
        "    else:\n",
        "        print(f\"Dataset already available at: {base_dir}\")\n",
        "\n",
        "def load_paper_rock_scissors():\n",
        "\n",
        "    base_dir = \"paper-rock-scissors\"\n",
        "\n",
        "    retrieve_paper_rock_scissors(base_dir)\n",
        "\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "\n",
        "    # Mapeamento das classes\n",
        "    class_names = {\n",
        "        0: 'paper',\n",
        "        1: 'rock',\n",
        "        2: 'scissors'\n",
        "    }\n",
        "\n",
        "    for label, cls in class_names.items():\n",
        "        cls_dir = os.path.join(base_dir, cls)\n",
        "        if os.path.isdir(cls_dir):\n",
        "            for filename in os.listdir(cls_dir):\n",
        "                if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img_path = os.path.join(cls_dir, filename)\n",
        "                    try:\n",
        "                        # Carrega em escala de cinza\n",
        "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                        # Redimensiona para 128x128\n",
        "                        img_resized = cv2.resize(img, (128, 128))\n",
        "                        x_data.append(img_resized)\n",
        "                        y_data.append(label)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "    # Holdout 70/30 estratificado\n",
        "    X_train, X_test, y_train_split, y_test_split = train_test_split(\n",
        "        x_data, y_data,\n",
        "        test_size=0.3,\n",
        "        random_state=42,\n",
        "        stratify=y_data\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        np.array(X_train),\n",
        "        np.array(y_train_split),\n",
        "        np.array(X_test),\n",
        "        np.array(y_test_split),\n",
        "        class_names\n",
        "    )"
      ],
      "metadata": {
        "id": "B5BP0kjHtuks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def retrieve_vehicle(base_dir):\n",
        "    dataset_url = \"http://www.ppgia.pucpr.br/~aghochuli/vehicle.zip\"\n",
        "    zip_path = \"vehicle.zip\"\n",
        "\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(\"Downloading...\")\n",
        "        os.system(f\"wget -O {zip_path} {dataset_url}\")\n",
        "        os.system(f\"unzip {zip_path}\")\n",
        "        #os.remove(zip_path)\n",
        "        print(f\"Dataset extracted to: {base_dir}\")\n",
        "    else:\n",
        "        print(f\"Dataset already available at: {base_dir}\")\n",
        "\n",
        "def load_vehicle():\n",
        "    base_dir = \"vehicle\"\n",
        "    retrieve_vehicle(base_dir)\n",
        "\n",
        "    # Estrutura esperada\n",
        "    subsets = ['train', 'test']\n",
        "    class_names = {}\n",
        "    data = {}\n",
        "\n",
        "    for subset in subsets:\n",
        "        subset_dir = os.path.join(base_dir, subset)\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        if os.path.isdir(subset_dir):\n",
        "            classes = [d for d in os.listdir(subset_dir) if os.path.isdir(os.path.join(subset_dir, d))]\n",
        "            # Mapear classes para labels se ainda não mapeadas\n",
        "            for idx, cls in enumerate(classes):\n",
        "                if cls not in class_names.values():\n",
        "                    class_names[idx] = cls\n",
        "            # Carregar imagens\n",
        "            for label, cls in class_names.items():\n",
        "                cls_dir = os.path.join(subset_dir, cls)\n",
        "                if os.path.isdir(cls_dir):\n",
        "                    for filename in os.listdir(cls_dir):\n",
        "                        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                            img_path = os.path.join(cls_dir, filename)\n",
        "                            try:\n",
        "                                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                                img_resized = cv2.resize(img, (128, 128))\n",
        "                                x_data.append(img_resized)\n",
        "                                y_data.append(label)\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error loading image {img_path}: {e}\")\n",
        "        data[subset] = (np.array(x_data), np.array(y_data))\n",
        "\n",
        "    return data['train'][0], data['train'][1], data['test'][0], data['test'][1], class_names"
      ],
      "metadata": {
        "id": "LJ3UCnn6v0C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptors"
      ],
      "metadata": {
        "id": "jjqi9vCbVD6L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LWJvWeOj72du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "kCdD2lqtgVPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_swedish_leaf()\n",
        "#x_train, y_train, x_test, y_test, class_names = load_paper_rock_scissors()\n",
        "#x_train, y_train, x_test, y_test, class_names = load_vehicle()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "786AbjISnwAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_per_class = 10\n",
        "for cls in np.unique(y_train):\n",
        "    idxs = np.where(y_train == cls)[0]\n",
        "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "    imgs = [x_train[i] for i in idxs]\n",
        "    titles = [f\"{class_names[cls]} #{i+1}\" for i in range(samples_per_class)]\n",
        "    plot_sidebyside(imgs, titles=titles, colormap=\"gray\", figsize=(20, 10))"
      ],
      "metadata": {
        "id": "L3FUMyj9eqyu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}